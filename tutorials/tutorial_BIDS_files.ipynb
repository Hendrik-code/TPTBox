{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIDS_files\n",
    "\n",
    "### What is BIDS?\n",
    "\n",
    "BIDS is a special naming convention for files and folders. See https://bids-specification.readthedocs.io/en/stable/\n",
    "It determines where files are, and how they are named.\n",
    "\n",
    "BIDS_files are a datatype that automaticall incorporates the aforementioned BIDS convention.\n",
    "\n",
    "The BIDS_files can automatically create a BIDS compliant dataset and provides Object to filter and loop through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Dataset  does not start with 'dataset-'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/media/data/robert/datasets/spinegan_T2w/raw/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTPTBox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BIDS_Global_info\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# TODO Replace /media/data/robert/datasets/spinegan_T2w/raw/ with a BIDS compline data set path, where rawdata and derivatives are.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# You can parse multiple datasets and select what parent folder are read (e.g. rawdata, derivatives)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m bids_global_object \u001b[38;5;241m=\u001b[39m \u001b[43mBIDS_Global_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/media/data/robert/datasets/spinegan_T2w/raw/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrawdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrawdata_dixon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mderivatives\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43movl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# The Parser will inform you about every non standard files. To add additional key add them to additional_key list, so you don't get the msg that this is not a valid key\u001b[39;00m\n",
      "File \u001b[0;32m/media/hendrik/be5e95dd-27c8-4c31-adc5-7b75f8ebd5c5/data/hendrik/TPTBox/TPTBox/core/bids_files.py:193\u001b[0m, in \u001b[0;36mBIDS_Global_info.__init__\u001b[0;34m(self, datasets, parents, additional_key, verbose, clear, file_name_manipulation)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(ds)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 193\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(ds)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ps \u001b[38;5;129;01min\u001b[39;00m parents:\n\u001b[1;32m    195\u001b[0m         path \u001b[38;5;241m=\u001b[39m Path(ds, ps)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /media/data/robert/datasets/spinegan_T2w/raw/"
     ]
    }
   ],
   "source": [
    "# Lets import the class that represent a whole data set.\n",
    "from TPTBox import BIDS_Global_info\n",
    "\n",
    "# TODO Replace /media/data/robert/datasets/spinegan_T2w/raw/ with a BIDS compline data set path, where rawdata and derivatives are.\n",
    "# You can parse multiple datasets and select what parent folder are read (e.g. rawdata, derivatives)\n",
    "bids_global_object = BIDS_Global_info(\n",
    "    [\"/media/data/robert/datasets/spinegan_T2w/raw/\"],\n",
    "    [\"rawdata\", \"rawdata_dixon\", \"derivatives\"],\n",
    "    additional_key=[\"sequ\", \"seg\", \"ovl\"],\n",
    "    verbose=True,\n",
    ")\n",
    "# The Parser will inform you about every non standard files. To add additional key add them to additional_key list, so you don't get the msg that this is not a valid key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to iterate through a Bids dataset?\n",
    "\n",
    "BIDS splits data samples roughly into:\n",
    "- Subject: different patients\n",
    "- Sessions: one patient can have multiple scans\n",
    "\n",
    "You use enumerate_subjects to iterate over different, unique subjects.\n",
    "Then, you can use queries to apply various filters. If you use flatten=True, that means you filter inividual files, and not a group/family of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First loop: Loop over subjects\n",
    "for subject_name, subject_container in bids_global_object.enumerate_subjects(sort=True):\n",
    "    # Lets filter out in formation we don't want.\n",
    "    # Lets only search for CT images\n",
    "\n",
    "    # start the search, you can start multiple independent filters.\n",
    "    query = subject_container.new_query(flatten=True)\n",
    "    # We want to filter only now for individual files and not for a group of files (file family), so we set flatten=True\n",
    "\n",
    "    # This call removes all files that do not end with \"_ct.[filetype]\"\n",
    "    query.filter(\"format\", \"ct\")\n",
    "    # Lets remove all files that don't have a nifty.\n",
    "    query.filter(\"Filetype\", \"nii.gz\")\n",
    "\n",
    "    # now we can loop over the CT files.\n",
    "    for bids_file in query.loop_list(sort=True):\n",
    "        # finally we get a bids_file\n",
    "        print(\"CT BIDS file:\", bids_file)\n",
    "        # We will look at bids_files closer soon, lets just open the nifty as a nibabel.\n",
    "        nii = bids_file.open_nii()\n",
    "        print(\"shape of nii-file:\", nii.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a BIDS_file\n",
    "\n",
    "\n",
    "Terminologies:\n",
    "\n",
    "A BIDS conform path looks like this:\n",
    "[dataset                                   ]/[  parent   ]/[  subpath ]/[     file_name                                 ]\n",
    "\n",
    "Example:\n",
    "/media/data/robert/datasets/spinegan_T2w/raw/rawdata_dixon/spinegan0001/sub-spinegan0001_ses-20220527_sequ-202_ct.nii.gz\n",
    "\n",
    "A file has all the information to find relations to other files.\n",
    "Lets look at this file.\n",
    "\n",
    "\"sub-spinegan0001_ses-20220527_sequ-202_ct.nii.gz\"\n",
    "\n",
    "The ending consists of a filetype and a format:\n",
    "\n",
    "filetype: \"nii.gz\"\n",
    "format: ct\n",
    "\n",
    "The rest are key-value pairs (stored in info) split with \"_\" and look like this <key>-<value>.\n",
    "For example, \"sub-spinegan0001\" means the key is \"sub\" (standing for subject)\" and its value is \"spinegan0001\".\n",
    "\n",
    "The above sample filename yields:\n",
    "\n",
    "sub : spinegan0001 <- must be the first key\n",
    "ses : 20220527\n",
    "sequ: 202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find this information in the Bids_file\n",
    "\n",
    "print(\"\\nFull file name\")\n",
    "print(bids_file.file[\"nii.gz\"])\n",
    "print(\"\\nfiletypes\")\n",
    "print(bids_file.file.keys())\n",
    "print(\"\\nformat\")\n",
    "print(bids_file.format)\n",
    "print(\"\\nkey-value\")\n",
    "print(bids_file.info)\n",
    "\n",
    "print(\"\\n\\nparent\")\n",
    "print(bids_file.get_parent(\"nii.gz\"))\n",
    "print(\"\\nthe 4 path parts\")\n",
    "print(bids_file.get_path_decomposed())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file family\n",
    "\n",
    "Everyone needs a family! \n",
    "Files that are generated from others should belong to a family. We automatically find related files and cluster them into a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T14:02:47.205041Z",
     "start_time": "2023-04-04T14:02:47.202482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We consider a file not to be in the same family if there is at least one key that is different an in this list:\n",
      "['ses', 'sequ', 'acq', 'hemi', 'sample', 'ce', 'trc', 'stain', 'rec', 'res', 'run', 'desc', 'split']\n"
     ]
    }
   ],
   "source": [
    "from BIDS.bids_constants import sequence_splitting_keys\n",
    "\n",
    "print(\"We consider a file not to be in the same family if there is at least one key that is different an in this list:\")\n",
    "print(sequence_splitting_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First loop: Loop over subjects\n",
    "for subject_name, subject_container in bids_global_object.enumerate_subjects(sort=True):\n",
    "    # Lets search for CTs images and related files\n",
    "\n",
    "    query = subject_container.new_query(flatten=False)  # <- flatten=False means we search for family\n",
    "    # This call removes all families that do not have at least one file that end with \"_ct.[filetype]\"\n",
    "    query.filter(\"format\", \"ct\")\n",
    "    # Lets require a segmentation\n",
    "    query.filter(\"seg\", \"vert\")\n",
    "    query.filter(\"seg\", \"subreg\")\n",
    "\n",
    "    # now we can loop over the CT files.\n",
    "    for bids_family in query.loop_dict(sort=True):\n",
    "        # finally we get a bids_family\n",
    "        print(\"Files in this family:\", bids_family.get_key_len())\n",
    "        print(bids_family)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now collect the individual files by using the short key. Not that we can find multiple instances of a key\n",
    "# Usually it is just the \"format\" tag\n",
    "ct_file = bids_family[\"ct\"][0]\n",
    "# We could find multiple ct, so we return always a list.\n",
    "from BIDS.bids_constants import sequence_naming_keys\n",
    "\n",
    "print('These formats will be tagged on with \"_\", instead of replaced', sequence_naming_keys)\n",
    "# so a ..._seg-vert_msk.nii.gz will get the key: msk_seg-vert\n",
    "vert_seg = bids_family[\"msk_seg-vert\"][0]\n",
    "\n",
    "print(vert_seg.file[\"nii.gz\"])\n",
    "print(vert_seg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets generate a new file\n",
    "\n",
    "We can get new datapaths in bids-format by using <bids_file>.get_changed_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take an existing file\n",
    "ct_file = bids_family[\"ct\"][0]\n",
    "# 2 Tell the bids file what should be different from the current file, the rest will be copied\n",
    "path1 = ct_file.get_changed_path(\"nii.gz\", format=\"msk\", info={\"seg\": \"vert\"}, parent=\"derivatives\")\n",
    "print(\"Path1:\", path1)\n",
    "path2 = ct_file.get_changed_path(\"json\", format=\"msk\", info={\"seg\": \"vert\"}, path=\"ses-{ses}_sub-{sub}/{sequ}\", parent=\"rawdata\")\n",
    "print(\"Path1:\", path2)\n",
    "print(type(path2))\n",
    "# 3 Just use it as a normal path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running in true parallel\n",
    "\n",
    "Python runs only in one thread. You have to spawn new Thread with Parallel. Here is an example. You have to create a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TPTBox import BIDS_Global_info\n",
    "from joblib import Parallel, delayed\n",
    "from TPTBox import Subject_Container\n",
    "import time, random\n",
    "\n",
    "n_jobs = 10\n",
    "\n",
    "\n",
    "def __helper(subj_name, subject: Subject_Container):\n",
    "    time.sleep(random.random() * 0.1)\n",
    "    # TODO: here is what it should do for each subject\n",
    "    print(subj_name)\n",
    "\n",
    "\n",
    "# initialize BIDS dataset\n",
    "global_info = BIDS_Global_info(\n",
    "    [\"/media/data/robert/datasets/spinegan_T2w/raw\"],\n",
    "    [\"sourcedata\", \"rawdata\", \"rawdata_ct\", \"rawdata_dixon\", \"derivatives\"],\n",
    "    additional_key=[\"sequ\", \"seg\", \"ovl\", \"e\"],\n",
    "    clear=True,\n",
    ")\n",
    "\n",
    "# Call parallel, which starts a number of threads equal to n_jobs and those call __helper() for each subject in bids_dataset\n",
    "Parallel(n_jobs=n_jobs)(delayed(__helper)(subj_name, subject) for subj_name, subject in global_info.enumerate_subjects(sort=True))\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856182c64741417959fd46a52606ac399fe54e69ad9697a20c4f35644f875db1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
