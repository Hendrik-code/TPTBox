{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIDS_files\n",
    "\n",
    "### What is BIDS?\n",
    "\n",
    "BIDS is a special naming convention for files and folders. See https://bids-specification.readthedocs.io/en/stable/\n",
    "It determines where files are, and how they are named.\n",
    "\n",
    "BIDS_files are a datatype that automaticall incorporates the aforementioned BIDS convention.\n",
    "\n",
    "The BIDS_files can automatically create a BIDS compliant dataset and provides Object to filter and loop through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 8744   total= 87      \r"
     ]
    }
   ],
   "source": [
    "# Lets import the class that represent a whole data set.\n",
    "from TPTBox import BIDS_Global_info\n",
    "\n",
    "# TODO Replace /DATA/NAS/datasets_processed/CT_spine/dataset-rsna/ with a BIDS compline data set path, where rawdata and derivatives are.\n",
    "# You can parse multiple datasets and select what parent folder are read (e.g. rawdata, derivatives)\n",
    "ds_path = \"/DATA/NAS/datasets_processed/CT_spine/dataset-rsna/\"\n",
    "bids_global_object = BIDS_Global_info(\n",
    "    [ds_path],\n",
    "    [\"rawdata\", \"rawdata_dixon\", \"derivatives\"],\n",
    "    additional_key=[\"sequ\", \"seg\", \"ovl\"],\n",
    "    verbose=True,\n",
    ")\n",
    "# The Parser will inform you about every non standard files. To add additional key add them to additional_key list, so you don't get the msg that this is not a valid key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to iterate through a Bids dataset?\n",
    "\n",
    "BIDS splits data samples roughly into:\n",
    "- Subject: different patients\n",
    "- Sessions: one patient can have multiple scans\n",
    "\n",
    "You use enumerate_subjects to iterate over different, unique subjects.\n",
    "Then, you can use queries to apply various filters. If you use flatten=True, that means you filter inividual files, and not a group/family of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT BIDS file: sub-10633_ct.['json', 'nii.gz']\t parent = rawdata\n",
      "shape of nii-file: (512, 512, 429)\n"
     ]
    }
   ],
   "source": [
    "# First loop: Loop over subjects\n",
    "for subject_name, subject_container in bids_global_object.enumerate_subjects(sort=True):\n",
    "    # Lets filter out in formation we don't want.\n",
    "    # Lets only search for CT images\n",
    "\n",
    "    # start the search, you can start multiple independent filters.\n",
    "    query = subject_container.new_query(flatten=True)\n",
    "    # We want to filter only now for individual files and not for a group of files (file family), so we set flatten=True\n",
    "\n",
    "    # This call removes all files that do not end with \"_ct.[filetype]\"\n",
    "    query.filter(\"format\", \"ct\")\n",
    "    # Lets remove all files that don't have a nifty.\n",
    "    query.filter(\"Filetype\", \"nii.gz\")\n",
    "\n",
    "    # now we can loop over the CT files.\n",
    "    for bids_file in query.loop_list(sort=True):\n",
    "        # finally we get a bids_file\n",
    "        print(\"CT BIDS file:\", bids_file)\n",
    "        # We will look at bids_files closer soon, lets just open the nifty as a nibabel.\n",
    "        nii = bids_file.open_nii()\n",
    "        print(\"shape of nii-file:\", nii.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a BIDS_file\n",
    "\n",
    "\n",
    "Terminologies:\n",
    "\n",
    "A BIDS conform path looks like this:\n",
    "[dataset                  ]/[parent ]/[ subpath]/[     file_name                                 ]\n",
    "\n",
    "Example:\n",
    "/media/data/dataset-spinegan/rawdata/spinegan0001/sub-spinegan0001_ses-20220527_sequ-202_ct.nii.gz\n",
    "\n",
    "A file has all the information to find relations to other files.\n",
    "Lets look at this file.\n",
    "\n",
    "\"sub-spinegan0001_ses-20220527_sequ-202_ct.nii.gz\"\n",
    "\n",
    "The ending consists of a filetype and a format:\n",
    "\n",
    "- filetype: \"nii.gz\"\n",
    "- bids_format: ct\n",
    "\n",
    "The rest are key-value pairs (stored in info) split with \"_\" and look like this <key>-<value>.\n",
    "For example, \"sub-spinegan0001\" means the key is \"sub\" (standing for subject)\" and its value is \"spinegan0001\".\n",
    "\n",
    "The above sample filename yields:\n",
    "\n",
    "- sub : spinegan0001 <- must be the first key\n",
    "- ses : 20220527\n",
    "- sequ: 202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full file name\n",
      "/DATA/NAS/datasets_processed/CT_spine/dataset-rsna/rawdata/10633/ses-baseline/sub-10633_ct.nii.gz\n",
      "\n",
      "filetypes\n",
      "dict_keys(['json', 'nii.gz'])\n",
      "\n",
      "format\n",
      "ct\n",
      "\n",
      "key-value\n",
      "{'sub': '10633'}\n",
      "\n",
      "\n",
      "parent\n",
      "rawdata\n",
      "\n",
      "the 4 path parts\n",
      "(PosixPath('/DATA/NAS/datasets_processed/CT_spine/dataset-rsna'), 'rawdata', '10633/ses-baseline', 'sub-10633_ct.json')\n"
     ]
    }
   ],
   "source": [
    "# Lets find this information in the Bids_file\n",
    "\n",
    "print(\"\\nFull file name\")\n",
    "print(bids_file.file[\"nii.gz\"])\n",
    "print(\"\\nfiletypes\")\n",
    "print(bids_file.file.keys())\n",
    "print(\"\\nformat\")\n",
    "print(bids_file.format)\n",
    "print(\"\\nkey-value\")\n",
    "print(bids_file.info)\n",
    "\n",
    "print(\"\\n\\nparent\")\n",
    "print(bids_file.get_parent(\"nii.gz\"))\n",
    "print(\"\\nthe 4 path parts\")\n",
    "print(bids_file.get_path_decomposed())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file family\n",
    "\n",
    "Everyone needs a family! \n",
    "Files that are generated from others should belong to a family. We automatically find related files and cluster them into a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T14:02:47.205041Z",
     "start_time": "2023-04-04T14:02:47.202482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We consider a file not to be in the same family if there is at least one key that is different an in this list:\n",
      "['ses', 'sequ', 'acq', 'hemi', 'sample', 'ce', 'trc', 'stain', 'res', 'dir', 'run', 'split', 'chunk']\n",
      "You can change the splitting keys during initializing the BIDS_Global_info\n",
      "Found: 8744   total= 87      \r"
     ]
    }
   ],
   "source": [
    "from TPTBox.core.bids_constants import sequence_splitting_keys\n",
    "\n",
    "print(\"We consider a file not to be in the same family if there is at least one key that is different an in this list:\")\n",
    "print(sequence_splitting_keys)\n",
    "print(\"You can change the splitting keys during initializing the BIDS_Global_info\")\n",
    "sequence_splitting_keys = sequence_splitting_keys.copy()\n",
    "sequence_splitting_keys.remove(\"run\")\n",
    "\n",
    "bids_global_object = BIDS_Global_info(\n",
    "    [ds_path],\n",
    "    [\"rawdata\", \"rawdata_dixon\", \"derivatives\"],\n",
    "    additional_key=[\"sequ\", \"seg\", \"ovl\"],\n",
    "    verbose=True,\n",
    "    sequence_splitting_keys=sequence_splitting_keys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in this family: {'ct': 1, 'msk_seg-subreg': 1, 'ctd_seg-subreg': 1, 'snp': 1, 'msk_seg-vert': 1}\n",
      "ct                             : [sub-10633_ct.['json', 'nii.gz']\t parent = rawdata]\n",
      "msk_seg-subreg                 : [sub-10633_seg-subreg_msk.['nii.gz']\t parent = derivatives]\n",
      "ctd_seg-subreg                 : [sub-10633_seg-subreg_ctd.['json']\t parent = derivatives]\n",
      "snp                            : [sub-10633_snp-cor_snp.['png']\t parent = derivatives]\n",
      "msk_seg-vert                   : [sub-10633_seg-vert_msk.['nii.gz']\t parent = derivatives]\n"
     ]
    }
   ],
   "source": [
    "# First loop: Loop over subjects\n",
    "for subject_name, subject_container in bids_global_object.enumerate_subjects(sort=True):\n",
    "    # Lets search for CTs images and related files\n",
    "\n",
    "    query = subject_container.new_query(flatten=False)  # <- flatten=False means we search for family\n",
    "    # This call removes all families that do not have at least one file that end with \"_ct.[filetype]\"\n",
    "    query.filter(\"format\", \"ct\")\n",
    "    # Lets require a segmentation\n",
    "    query.filter(\"seg\", \"vert\")\n",
    "    query.filter(\"seg\", \"subreg\")\n",
    "\n",
    "    # now we can loop over the CT files.\n",
    "    for bids_family in query.loop_dict(sort=True):\n",
    "        # finally we get a bids_family\n",
    "        print(\"Files in this family:\", bids_family.get_key_len())\n",
    "        print(bids_family)\n",
    "        break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These formats will be tagged on with \"_\", instead of replaced ['seg', 'label']\n",
      "/DATA/NAS/datasets_processed/CT_spine/dataset-rsna/derivatives/10633/ses-baseline/sub-10633_seg-vert_msk.nii.gz\n",
      "sub-10633_seg-vert_msk.['nii.gz']\t parent = derivatives\n"
     ]
    }
   ],
   "source": [
    "from TPTBox.core.bids_constants import sequence_naming_keys\n",
    "# We can now collect the individual files by using the short key. Not that we can find multiple instances of a key\n",
    "# Usually it is just the \"format\" tag\n",
    "ct_file = bids_family[\"ct\"][0]\n",
    "# We could find multiple ct, so we return always a list.\n",
    "\n",
    "\n",
    "print('These formats will be tagged on with \"_\"', sequence_naming_keys)\n",
    "# so a ..._seg-vert_msk.nii.gz will get the key: msk_seg-vert\n",
    "vert_seg = bids_family[\"msk_seg-vert\"][0]\n",
    "\n",
    "print(vert_seg.file[\"nii.gz\"])\n",
    "print(vert_seg)\n",
    "\n",
    "print(\"You\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets generate a new file\n",
    "\n",
    "We can get new datapaths in bids-format by using <bids_file>.get_changed_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path1: /DATA/NAS/datasets_processed/CT_spine/dataset-rsna/derivatives/10633/ses-baseline/sub-10633_seg-vert_msk.nii.gz\n",
      "Path1: /DATA/NAS/datasets_processed/CT_spine/dataset-rsna/rawdata/ses-ses_sub-10633/sequ/sub-10633_seg-vert_msk.json\n",
      "<class 'pathlib.PosixPath'>\n",
      "sub-10633_seg-vert_msk.['nii.gz']\t parent = derivatives\n",
      "sub-10633_seg-vert_msk.['nii.gz']\t parent = derivatives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "/tmp/ipykernel_3550418/451550993.py:10: UserWarning: ses not found in sub-10633_ct.['json', 'nii.gz']\t parent = rawdata\n",
      "  path2 = ct_file.get_changed_path(\"json\", bids_format=\"msk\", info={\"seg\": \"vert\"}, path=\"ses-{ses}_sub-{sub}/{sequ}\", parent=\"rawdata\",make_parent=False)\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3550418/451550993.py\", line 10, in <module>\n",
      "    path2 = ct_file.get_changed_path(\"json\", bids_format=\"msk\", info={\"seg\": \"vert\"}, path=\"ses-{ses}_sub-{sub}/{sequ}\", parent=\"rawdata\",make_parent=False)\n",
      "  File \"/DATA/NAS/tools/TPTBox/TPTBox/core/bids_files.py\", line 580, in get_changed_path\n",
      "    path = self.insert_info_into_path(path)\n",
      "  File \"/DATA/NAS/tools/TPTBox/TPTBox/core/bids_files.py\", line 737, in insert_info_into_path\n",
      "    warn(f\"{middle} not found in {self}\", stacklevel=3)\n",
      "####################################\n",
      "####################################\n",
      "/tmp/ipykernel_3550418/451550993.py:10: UserWarning: sequ not found in sub-10633_ct.['json', 'nii.gz']\t parent = rawdata\n",
      "  path2 = ct_file.get_changed_path(\"json\", bids_format=\"msk\", info={\"seg\": \"vert\"}, path=\"ses-{ses}_sub-{sub}/{sequ}\", parent=\"rawdata\",make_parent=False)\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3550418/451550993.py\", line 10, in <module>\n",
      "    path2 = ct_file.get_changed_path(\"json\", bids_format=\"msk\", info={\"seg\": \"vert\"}, path=\"ses-{ses}_sub-{sub}/{sequ}\", parent=\"rawdata\",make_parent=False)\n",
      "  File \"/DATA/NAS/tools/TPTBox/TPTBox/core/bids_files.py\", line 580, in get_changed_path\n",
      "    path = self.insert_info_into_path(path)\n",
      "  File \"/DATA/NAS/tools/TPTBox/TPTBox/core/bids_files.py\", line 737, in insert_info_into_path\n",
      "    warn(f\"{middle} not found in {self}\", stacklevel=3)\n",
      "####################################\n"
     ]
    }
   ],
   "source": [
    "# 1. Take an existing file\n",
    "from TPTBox.core.bids_files import BIDS_FILE\n",
    "\n",
    "\n",
    "ct_file = bids_family[\"ct\"][0]\n",
    "# 2 Tell the bids file what should be different from the current file, the rest will be copied\n",
    "path1 = ct_file.get_changed_path(\"nii.gz\", bids_format=\"msk\", info={\"seg\": \"vert\"}, parent=\"derivatives\",make_parent=False)\n",
    "print(\"Path1:\", path1)\n",
    "# You can set the path and use key information with the following syntax:\n",
    "path2 = ct_file.get_changed_path(\"json\", bids_format=\"msk\", info={\"seg\": \"vert\"}, path=\"ses-{ses}_sub-{sub}/{sequ}\", parent=\"rawdata\",make_parent=False)\n",
    "print(\"Path1:\", path2)\n",
    "print(type(path2))\n",
    "# 3 Just use it as a normal path\n",
    "\n",
    "# If you want make a new file handle as a BIDS file you can use:\n",
    "bids1 = ct_file.get_changed_bids(\"nii.gz\", bids_format=\"msk\", info={\"seg\": \"vert\"}, parent=\"derivatives\",make_parent=False)\n",
    "print(bids1)\n",
    "# or create a new BIDS FILE\n",
    "bids2 = BIDS_FILE(path1,ct_file.dataset)\n",
    "print(bids2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running in true parallel\n",
    "\n",
    "Python runs only in one thread. You have to spawn new Thread with Parallel. Here is an example. You have to create a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363d: 8744   total= 87      \n",
      "11988\n",
      "12833\n",
      "10921\n",
      "11827\n",
      "10633\n",
      "16919\n",
      "15206\n",
      "12281\n",
      "16092\n",
      "17960\n",
      "14267\n",
      "1573\n",
      "12292\n",
      "18480\n",
      "1542\n",
      "17481\n",
      "1868\n",
      "1480\n",
      "19333\n",
      "18935\n",
      "19388\n",
      "2243\n",
      "18906\n",
      "20647\n",
      "23904\n",
      "20928\n",
      "20120\n",
      "25704\n",
      "19021\n",
      "21321\n",
      "24140\n",
      "18968\n",
      "26110\n",
      "24606\n",
      "21651\n",
      "24891\n",
      "26442\n",
      "26068\n",
      "26898\n",
      "25833\n",
      "27752\n",
      "24617\n",
      "26990\n",
      "26979\n",
      "30067\n",
      "29425\n",
      "30524\n",
      "27016\n",
      "26498\n",
      "26492\n",
      "26740\n",
      "31077\n",
      "3168\n",
      "27292\n",
      "28327\n",
      "32590\n",
      "28025\n",
      "30487\n",
      "28665\n",
      "5671\n",
      "32071\n",
      "5783\n",
      "5782\n",
      "32658\n",
      "3992\n",
      "30640\n",
      "32280\n",
      "30565\n",
      "780\n",
      "3376\n",
      "8024\n",
      "6125\n",
      "32434\n",
      "8330\n",
      "4769\n",
      "4202\n",
      "8744\n",
      "6078\n",
      "6376\n",
      "8884\n",
      "8574\n",
      "9926\n",
      "32370\n",
      "5002\n",
      "3882\n",
      "32436\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import time, random\n",
    "from TPTBox import BIDS_Global_info,Subject_Container\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "n_jobs = 10\n",
    "\n",
    "\n",
    "def __helper(subj_name, subject: Subject_Container):\n",
    "    time.sleep(random.random() * 0.1)\n",
    "    # TODO: here is what it should do for each subject\n",
    "    print(subj_name)\n",
    "\n",
    "\n",
    "# initialize BIDS dataset\n",
    "global_info = BIDS_Global_info(\n",
    "    [ds_path],\n",
    "    [\"sourcedata\", \"rawdata\", \"rawdata_ct\", \"rawdata_dixon\", \"derivatives\"],\n",
    "    additional_key=[\"sequ\", \"seg\", \"ovl\", \"e\"],\n",
    ")\n",
    "\n",
    "# Call parallel, which starts a number of threads equal to n_jobs and those call __helper() for each subject in bids_dataset\n",
    "Parallel(n_jobs=n_jobs)(delayed(__helper)(subj_name, subject) for subj_name, subject in global_info.enumerate_subjects(sort=True))\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856182c64741417959fd46a52606ac399fe54e69ad9697a20c4f35644f875db1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
